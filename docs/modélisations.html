<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Modélisations | Prédire le prix des maisons présentant plusieurs caractéristiques</title>
  <meta name="description" content="3 Modélisations | Prédire le prix des maisons présentant plusieurs caractéristiques" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Modélisations | Prédire le prix des maisons présentant plusieurs caractéristiques" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Modélisations | Prédire le prix des maisons présentant plusieurs caractéristiques" />
  
  
  

<meta name="author" content="Axel-Cleris Gailloty" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analyse-exploratoire-des-données.html"/>
<link rel="next" href="comparaison-des-performances-des-différentes-méthodes-destimation.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction-générale.html"><a href="introduction-générale.html"><i class="fa fa-check"></i><b>1</b> Introduction générale</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-générale.html"><a href="introduction-générale.html#présentation-des-données"><i class="fa fa-check"></i><b>1.1</b> Présentation des données</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-générale.html"><a href="introduction-générale.html#objectifs-de-létude"><i class="fa fa-check"></i><b>1.2</b> Objectifs de l’étude</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-générale.html"><a href="introduction-générale.html#plan-de-létude"><i class="fa fa-check"></i><b>1.3</b> Plan de l’étude</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-exploratoire-des-données.html"><a href="analyse-exploratoire-des-données.html"><i class="fa fa-check"></i><b>2</b> Analyse exploratoire des données</a><ul>
<li class="chapter" data-level="2.1" data-path="analyse-exploratoire-des-données.html"><a href="analyse-exploratoire-des-données.html#statistiques-descriptives-univariées"><i class="fa fa-check"></i><b>2.1</b> Statistiques descriptives univariées</a></li>
<li class="chapter" data-level="2.2" data-path="analyse-exploratoire-des-données.html"><a href="analyse-exploratoire-des-données.html#statistiques-descriptives-bivariées"><i class="fa fa-check"></i><b>2.2</b> Statistiques descriptives bivariées</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-exploratoire-des-données.html"><a href="analyse-exploratoire-des-données.html#lanalyse-en-composantes-principales"><i class="fa fa-check"></i><b>2.3</b> L’analyse en composantes principales</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modélisations.html"><a href="modélisations.html"><i class="fa fa-check"></i><b>3</b> Modélisations</a><ul>
<li class="chapter" data-level="3.1" data-path="modélisations.html"><a href="modélisations.html#transformations-des-données"><i class="fa fa-check"></i><b>3.1</b> Transformations des données</a></li>
<li class="chapter" data-level="3.2" data-path="modélisations.html"><a href="modélisations.html#modèle-de-régression-multiple"><i class="fa fa-check"></i><b>3.2</b> Modèle de régression multiple</a><ul>
<li class="chapter" data-level="3.2.1" data-path="modélisations.html"><a href="modélisations.html#le-test-dinflation-de-la-variance-vif"><i class="fa fa-check"></i><b>3.2.1</b> Le test d’inflation de la variance (VIF)</a></li>
<li class="chapter" data-level="3.2.2" data-path="modélisations.html"><a href="modélisations.html#vérifions-lhypothèse-de-normalité-des-résidus"><i class="fa fa-check"></i><b>3.2.2</b> Vérifions l’hypothèse de normalité des résidus</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="modélisations.html"><a href="modélisations.html#régressions-sur-variables-latentes"><i class="fa fa-check"></i><b>3.3</b> Régressions sur variables latentes</a><ul>
<li class="chapter" data-level="3.3.1" data-path="modélisations.html"><a href="modélisations.html#pourquoi-faire-une-régression-sur-les-variables-latentes"><i class="fa fa-check"></i><b>3.3.1</b> Pourquoi faire une régression sur les variables latentes ?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="modélisations.html"><a href="modélisations.html#régréssion-sur-composantes-principales"><i class="fa fa-check"></i><b>3.4</b> Régréssion sur composantes principales</a></li>
<li class="chapter" data-level="3.5" data-path="modélisations.html"><a href="modélisations.html#résultats-destimations-avec-sas"><i class="fa fa-check"></i><b>3.5</b> Résultats d’estimations avec SAS</a><ul>
<li class="chapter" data-level="3.5.1" data-path="modélisations.html"><a href="modélisations.html#régéressions-sur-les-moindres-carrés-partiels"><i class="fa fa-check"></i><b>3.5.1</b> Régéressions sur les moindres carrés partiels</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="comparaison-des-performances-des-différentes-méthodes-destimation.html"><a href="comparaison-des-performances-des-différentes-méthodes-destimation.html"><i class="fa fa-check"></i><b>4</b> Comparaison des performances des différentes méthodes d’estimation</a></li>
<li class="chapter" data-level="5" data-path="bibliographie.html"><a href="bibliographie.html"><i class="fa fa-check"></i><b>5</b> Bibliographie</a></li>
<li class="chapter" data-level="6" data-path="annexes.html"><a href="annexes.html"><i class="fa fa-check"></i><b>6</b> Annexes</a><ul>
<li class="chapter" data-level="6.1" data-path="annexes.html"><a href="annexes.html#annexe-1-liste-exhaustive-des-colonnes"><i class="fa fa-check"></i><b>6.1</b> Annexe 1 : Liste exhaustive des colonnes</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Prédire le prix des maisons présentant plusieurs caractéristiques</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modélisations" class="section level1">
<h1><span class="header-section-number">3</span> Modélisations</h1>
<div id="transformations-des-données" class="section level2">
<h2><span class="header-section-number">3.1</span> Transformations des données</h2>
<p>Comme nous l’avions présenté dans la présentation des données, 46 des colonnes présentes dans le jeu de données ne sont pas quantitatives et continues. En effet 23 sont qualitatives ordinales et 23 autres sont qualitatives simples. Il est donc important que nous trouvions une stratégie pour inclure ces colonnes dans le modèle car ces informations qui ne sont pas nécessairement quantitatives sont importantes pour comprendre l’inertie de la variable que nous cherchons à modéliser qui est en l’occurrence le prix du bien immobilier (<code>Sale_Price</code>).</p>
<p>Pour nous assurer de l’importance d’inclure les variables non quantitatives dans le modèle, nous allons construire deux modèles de régression multiples simples. Le premier modèle inclut uniquement les variables quantitatives continues et le second modèle va inclure en plus des variables quantitatives les variables qualitatives transformées.</p>
</div>
<div id="modèle-de-régression-multiple" class="section level2">
<h2><span class="header-section-number">3.2</span> Modèle de régression multiple</h2>
<pre><code>
Call:
lm(formula = Sale_Price ~ ., data = base_export)

Residuals:
    Min      1Q  Median      3Q     Max 
-611577  -18168   -1914   15215  291823 

Coefficients: (1 not defined because of singularities)
                       Estimate   Std. Error t value Pr(&gt;|t|)    
(Intercept)         173248.3794 1034265.8314    0.17  0.86698    
Lot_Frontage            87.8031      21.0713    4.17  3.2e-05 ***
Lot_Area                 0.2765       0.0926    2.98  0.00286 ** 
Year_Built             366.0522      40.8997    8.95  &lt; 2e-16 ***
Year_Remod_Add         520.8040      43.8314   11.88  &lt; 2e-16 ***
Mas_Vnr_Area            39.2747       4.3907    8.94  &lt; 2e-16 ***
BsmtFin_SF_1           120.5512     399.7987    0.30  0.76303    
BsmtFin_SF_2           -11.0815       4.2313   -2.62  0.00887 ** 
Bsmt_Unf_SF            -12.3113       2.6685   -4.61  4.1e-06 ***
Total_Bsmt_SF           37.9704       3.3100   11.47  &lt; 2e-16 ***
First_Flr_SF            61.3303       4.0088   15.30  &lt; 2e-16 ***
Second_Flr_SF           60.4504       3.5406   17.07  &lt; 2e-16 ***
Low_Qual_Fin_SF         12.8328      14.7913    0.87  0.38569    
Gr_Liv_Area                  NA           NA      NA       NA    
Bsmt_Full_Bath        6293.2883    1856.1886    3.39  0.00071 ***
Bsmt_Half_Bath       -1858.6131    2914.0839   -0.64  0.52365    
Full_Bath             1920.7409    1998.4969    0.96  0.33659    
Half_Bath            -2438.2657    1935.2284   -1.26  0.20779    
Bedroom_AbvGr        -9685.3490    1216.2710   -7.96  2.4e-15 ***
Kitchen_AbvGr       -34847.2817    3621.0884   -9.62  &lt; 2e-16 ***
TotRms_AbvGrd         4500.6690     881.1315    5.11  3.5e-07 ***
Fireplaces            7560.9687    1265.2644    5.98  2.6e-09 ***
Garage_Cars           8144.4884    2093.4707    3.89  0.00010 ***
Garage_Area             20.9141       7.2152    2.90  0.00378 ** 
Wood_Deck_SF            23.0064       5.7959    3.97  7.4e-05 ***
Open_Porch_SF           -6.8497      10.8546   -0.63  0.52806    
Enclosed_Porch          27.8903      11.4544    2.43  0.01496 *  
Three_season_porch      10.0811      26.5688    0.38  0.70439    
Screen_Porch            62.8680      12.2964    5.11  3.4e-07 ***
Pool_Area              -67.5348      19.3964   -3.48  0.00051 ***
Misc_Val                -9.6839       1.1967   -8.09  8.5e-16 ***
Mo_Sold                 87.9764     249.1791    0.35  0.72407    
Year_Sold             -941.5430     514.1045   -1.83  0.06714 .  
Overall_Qual          4832.1477    1133.1679    4.26  2.1e-05 ***
Overall_Cond         -2726.7366    1385.2232   -1.97  0.04911 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 35900 on 2896 degrees of freedom
Multiple R-squared:  0.801, Adjusted R-squared:  0.798 
F-statistic:  353 on 33 and 2896 DF,  p-value: &lt;2e-16</code></pre>
<p>La significativité globale de ce modèle de régression multiple est très bonne comme l’indique le test de Fisher. Le modèle explique 80% de la variance des prix de vente, ce qui est très bien pour des données transversales. La grande majorité des variables que nous avions sélectionnées pour inclure dans le modèle se sont montrés significatifs. Le test de Student effectué sur chacun des coefficients montre les différents dégrés de significativités des coefficients.</p>
<p>A cause de multicolinéarité, la variable <code>Gr_Liv_Area</code> qui représente la surface habitable hors étage de la maison a été enlevée du modèle.</p>
<p>Les variables sont toutes en niveau, nous pouvons donc interpréter les coefficients dans l’unité de la variable. Par exemple l’augmentation de la superficie du terrain (<code>Lot_Area</code>) d’un pied carré augmente le prix de la maison de 87.8 dollars, toute chose égale par ailleurs.</p>
<div id="le-test-dinflation-de-la-variance-vif" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Le test d’inflation de la variance (VIF)</h3>
<p>Il n’est pas possible de réaliser le test d’inflation de la variance (<em>Variance Inflation Factor</em>) sur le modèle car le coefficient de la variable <code>Gr_Liv_Area</code> n’a pas été calculé à cause de la multicolinéarité. Pour pouvoir quantifier la multicolinéarité entre les variables, nous devons donc estimer un nouveau modèle dans lequel la variable <code>Gr_Liv_Area</code> est absente.</p>
<p>Voici donc les résultats du test VIF que trouvons lorsque la variable <code>Gr_Liv_Area</code> est omise.</p>
<table>
<caption><span id="tab:unnamed-chunk-18">Table 3.1: </span>Test d’inflation de la variance (VIF)</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">VIF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Garage_Cars</td>
<td align="right">5.7824</td>
</tr>
<tr class="even">
<td>First_Flr_SF</td>
<td align="right">5.6211</td>
</tr>
<tr class="odd">
<td>Garage_Area</td>
<td align="right">5.4902</td>
</tr>
<tr class="even">
<td>Second_Flr_SF</td>
<td align="right">5.2394</td>
</tr>
<tr class="odd">
<td>Total_Bsmt_SF</td>
<td align="right">4.8521</td>
</tr>
<tr class="even">
<td>TotRms_AbvGrd</td>
<td align="right">4.3749</td>
</tr>
<tr class="odd">
<td>Year_Built</td>
<td align="right">3.4851</td>
</tr>
<tr class="even">
<td>Bsmt_Unf_SF</td>
<td align="right">3.1331</td>
</tr>
<tr class="odd">
<td>Full_Bath</td>
<td align="right">2.7811</td>
</tr>
<tr class="even">
<td>Bedroom_AbvGr</td>
<td align="right">2.3083</td>
</tr>
<tr class="odd">
<td>Bsmt_Full_Bath</td>
<td align="right">2.1608</td>
</tr>
<tr class="even">
<td>Half_Bath</td>
<td align="right">2.1548</td>
</tr>
<tr class="odd">
<td>Year_Remod_Add</td>
<td align="right">1.9040</td>
</tr>
<tr class="even">
<td>BsmtFin_SF_1</td>
<td align="right">1.8158</td>
</tr>
<tr class="odd">
<td>Overall_Cond</td>
<td align="right">1.5940</td>
</tr>
<tr class="even">
<td>Fireplaces</td>
<td align="right">1.5306</td>
</tr>
<tr class="odd">
<td>Mas_Vnr_Area</td>
<td align="right">1.4011</td>
</tr>
<tr class="even">
<td>Kitchen_AbvGr</td>
<td align="right">1.3686</td>
</tr>
<tr class="odd">
<td>Enclosed_Porch</td>
<td align="right">1.2293</td>
</tr>
<tr class="even">
<td>Open_Porch_SF</td>
<td align="right">1.2220</td>
</tr>
<tr class="odd">
<td>Wood_Deck_SF</td>
<td align="right">1.2216</td>
</tr>
<tr class="even">
<td>Lot_Area</td>
<td align="right">1.2132</td>
</tr>
<tr class="odd">
<td>BsmtFin_SF_2</td>
<td align="right">1.1666</td>
</tr>
<tr class="even">
<td>Bsmt_Half_Bath</td>
<td align="right">1.1625</td>
</tr>
<tr class="odd">
<td>Overall_Qual</td>
<td align="right">1.1516</td>
</tr>
<tr class="even">
<td>Lot_Frontage</td>
<td align="right">1.1348</td>
</tr>
<tr class="odd">
<td>Pool_Area</td>
<td align="right">1.0857</td>
</tr>
<tr class="even">
<td>Screen_Porch</td>
<td align="right">1.0833</td>
</tr>
<tr class="odd">
<td>Low_Qual_Fin_SF</td>
<td align="right">1.0686</td>
</tr>
<tr class="even">
<td>Misc_Val</td>
<td align="right">1.0461</td>
</tr>
<tr class="odd">
<td>Year_Sold</td>
<td align="right">1.0434</td>
</tr>
<tr class="even">
<td>Mo_Sold</td>
<td align="right">1.0420</td>
</tr>
<tr class="odd">
<td>Three_season_porch</td>
<td align="right">1.0162</td>
</tr>
</tbody>
</table>
<p>Puisqu’il n’y a aucune valeur VIF supérieure à 10, il est tentant d’affirmer qu’il n’y a pas de multicolinéarité. Car nous avons vu dans l’analyse des corrélations que certaines variables étaient fortement corrélées. Ainsi bien qu’il n’y a pas de relation linéaire exacte entre les variables, il existe des pseudo-colinéarités relativement fortes entre les variables.</p>
<p>Nous pouvons vérifier les autres hypothèses des OLS pour déduire la colinéarité.</p>
</div>
<div id="vérifions-lhypothèse-de-normalité-des-résidus" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Vérifions l’hypothèse de normalité des résidus</h3>
<p>Nous pouvons représenter un histogramme de la distribution des résidus du modèle que nous venons d’estimer. L’une des hypothèses importantes des MCO est la normalité des résidus. Nous pouvons visuellement à l’aide de l’histogramme des résidus dire si les résidus suivent une loi normale.</p>
<p><img src="main_files/figure-html/unnamed-chunk-19-1.png" width="2400" />
A l’aide de l’histogramme nous observons que la distribution ressemble à une loi normale, mais elle est fortement dirigée vers la droite.
Nous pouvons faire le test de Shapiro-Wilk pour tester plus formellement la normalité des résidus. L’hypothèse nulle de ce test est que la distribution est normalement distribuée.</p>
<pre><code>
    Shapiro-Wilk normality test

data:  mod$residuals
W = 0.812, p-value &lt;2e-16</code></pre>
<p>Ici la p-value est inférieure à 5% donc, nous rejettons cette hypothèse nulle, la distribution ne suit pas une loi normale.</p>
<p>Dès lors que les résidus ne suivent pas une loi normale, les estimations faites par les OLS sont biaisées. Il importe donc d’utiliser d’autres méthodes d’estimations pour construire le modèle.</p>
</div>
</div>
<div id="régressions-sur-variables-latentes" class="section level2">
<h2><span class="header-section-number">3.3</span> Régressions sur variables latentes</h2>
<div id="pourquoi-faire-une-régression-sur-les-variables-latentes" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Pourquoi faire une régression sur les variables latentes ?</h3>
<p>Les méthodes de régressions sur les latentes nous permettent d’adresser certaines limites que posent les méthodes de régression sur les moindres carrés. En effet pour qu’une régression par les OLS soit sans biais il faut que les hypothèses posées par les OLS soit vérifiées. Parmi ces hypothèses nous pouvons citer l’absence de corrélations entre les variables et l’absence de multicolinéarité entre les variables.</p>
<p>Or en général les phénomènes que nous cherchons à expliquer, ici le prix de vente du bien immobilier, ne vérifient pas toujours ces hypothèses à cause entre autres de la non indépendance des phénomènes. Cette situation nous amène à des résultats potentiellement biasés et non généralisables pour expliquer le phénomène.
La méthode de régression sur les variables nous permettent donc de corriger ces limites des régression standards en créant des variables synthétiques sur lesquelles nous allons faire les estimations.
Les variables synthétiques créées lors de l’estimation présentent une propriété très intéressante qui est celle de l’orthogonalité. En effet les variables synthétiques ou les composantes ne sont pas corrélées entre elles-mêmes, ce faisant nous pouvons entièrement faire des régressions en vérifiant les hypothèses des OLS standards.</p>
<p>Pour mettre en place ces méthodes, nous allons utiliser la procédure PLS implémentée dans le logiciel SAS.</p>
<p>Les techniques mises en œuvre par la procédure PLS sont les suivantes:</p>
<ul>
<li><p>La régression sur composantes principales, qui extrait des facteurs qui expliquent le plus la variance des variables explicatives.</p></li>
<li><p>La régression de rang réduit, qui extrait des facteurs qui expliquent le plus la variation de la variable réponse (y). Cette technique, également appelée analyse de redondance (maximale), diffère de la régression linéaire multivariée uniquement lorsqu’il y a plusieurs réponses.</p></li>
<li><p>La régression sur les moindres carrés partiels, qui équilibre les deux objectifs d’explication de la variation de la réponse et expliquant la variation des prédicteurs. Deux formulations différentes pour les moindres carrés partiels sont disponibles:
la méthode prédictive originale de Wold (1966) et la méthode SIMPLS de de Jong (1993).</p></li>
</ul>
<p>En raison du fait que nous ne cherchons ici qu’à expliquer une seule variable (y), à savoir le prix des maisons, nous n’utiliserons pas la régression sur rang réduit.</p>
</div>
</div>
<div id="régréssion-sur-composantes-principales" class="section level2">
<h2><span class="header-section-number">3.4</span> Régréssion sur composantes principales</h2>
<p>La méthode de régression sur composantes principales consiste à effectuer une régression linéaire simple ou multiple sur les coordonnées des individus projetés dans un plan factoriel à k dimensions avec k strictement plus petit que le nombre de variables initial.</p>
<p>Pour cette méthode, nous allons utiliser conjointement SAS et R.</p>
</div>
<div id="résultats-destimations-avec-sas" class="section level2">
<h2><span class="header-section-number">3.5</span> Résultats d’estimations avec SAS</h2>
<p><img src="pcr-img/pcr_general_info.PNG" /></p>
<p><img src="pcr-img/pcr_split-sample.PNG" /></p>
<p>Pour pouvoir déterminer avec confiance le nombre de composantes principales (ou facteurs) à retenir dans la PCR, l’algorithme utilise une technique de validation croisée. Une technique de validation croisée consiste à diviser l’échantillon en plusieurs groupes sur lesquels des ajustements successifs sont effectués. L’ajustement du modèle est effectué sur le groupe d’apprentissage et les résultats sont comparés aux observations du groupe test. L’efficaité prédictive est évaluée à l’aide l’indicateur PRESS (Predicted REsidual Sum of Squares).
Le tableau suivant nous montre que la valeur minimale de la validation croisée est atteinte si le nombre de composantes principales est 8. Toutefois il est préférable de se fier au test qui indique si oui ou non il existe une différence significative entre les 8 composantes.<br />
Le test nous indique qu’à partir de la 4e composante il n’existe plus de différences significatives entre les composantes. Nous allons donc retenir 5 composantes pour la suite de l’analyse.</p>
<p><img src="pcr-img/pcr_analysis_val_crois.png" /></p>
<p>Il convient maintenant d’interpréter les résultats du modèle construit.
Le tableau suivant affiche la variation de pourcentage expliquée par composantes principales</p>
<p><img src="pcr-img/pcr_results.PNG" /></p>
<p>Le tableau affiche deux catégories de résultats : la variation de pourcentage expliquée par composantes principales sur les effets du modèle et sur la variable dépendante.
Les effets du modèle représentent les variables explicatives tandis que la variable dépendante est le prix de la maison que nous cherchons à expliquer.</p>
<p>Nous voyons donc que pour les 5 composantes retenues, la régression sur les composantes principales explique près de 76% de la variable dépendante et environ 43% des variables explicatives.</p>
<p>Nous pouvons à partir d’ici utiliser R pour trouver les coefficients associés à chaque facteur extrait.</p>
<pre><code>
Call:
lm(formula = Sale_Price ~ ., data = coord_pc)

Residuals:
    Min      1Q  Median      3Q     Max 
-535355  -20542   -3320   17245  304779 

Coefficients:
            Estimate Std. Error t value    Pr(&gt;|t|)    
(Intercept)   180796        725  249.50     &lt; 2e-16 ***
Dim.1          27396        292   93.94     &lt; 2e-16 ***
Dim.2          -7046        416  -16.95     &lt; 2e-16 ***
Dim.3            479        498    0.96        0.34    
Dim.4           2779        513    5.41 0.000000066 ***
Dim.5           5770        629    9.17     &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 39200 on 2924 degrees of freedom
Multiple R-squared:  0.759, Adjusted R-squared:  0.759 
F-statistic: 1.85e+03 on 5 and 2924 DF,  p-value: &lt;2e-16</code></pre>
<p>Les résultats globaux du modèle que nous trouvons sont les mêmes avec R. Les 5 composantes retenues expliquent bien 75,93% de la variance des prix de vente de la maison.</p>
<div id="régéressions-sur-les-moindres-carrés-partiels" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Régéressions sur les moindres carrés partiels</h3>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analyse-exploratoire-des-données.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparaison-des-performances-des-différentes-méthodes-destimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

</body>

</html>
